{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFe0WMGHEaPPOKlajVgTah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepavasanthkumar/spark_tips/blob/main/Python_user_defined_table_function_udtf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4C28KgO1iOu",
        "outputId": "2b7c7dc1-c90a-419f-f4ba-33df45707547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=5bcd4e51013412005a64be535080c705c874c908b60791b9b8f58abcfbe5b00e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "  .master(\"local\")\n",
        "  .appName(\"PySpark User Defined Table Functions\")\n",
        "  .getOrCreate())"
      ],
      "metadata": {
        "id": "188sS5oR4Kou"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python user-defined table function (UDTF)**\n",
        "\n",
        " a new type of user-defined function. Unlike scalar functions that return a single result value from each call, each UDTF is invoked in the FROM clause of a query and returns an entire table as output. Each UDTF call can accept zero or more arguments. These arguments can either be scalar expressions or table arguments that represent entire input tables."
      ],
      "metadata": {
        "id": "NV2jg4nS5aOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udtf\n",
        "\n",
        "@udtf(returnType=\"word: string\")\n",
        "class WordSplitter:\n",
        "    def eval(self, text: str):\n",
        "        for word in text.split(\" \"):\n",
        "            yield (word.strip(),)\n",
        "\n",
        "# Register the UDTF for use in Spark SQL.\n",
        "spark.udtf.register(\"split_words\", WordSplitter)\n",
        "\n",
        "# Example: Using the UDTF in SQL.\n",
        "spark.sql(\"SELECT * FROM split_words('hello world')\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an61YIdN2G5H",
        "outputId": "78d4b447-f3e7-404f-c145-50d8b57a5840"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| word|\n",
            "+-----+\n",
            "|hello|\n",
            "|world|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the UDTF with a lateral join in SQL**\n",
        "\n",
        "The lateral join allows us to reference the columns and aliases\n",
        "in the previous FROM clause items as inputs to the UDTF."
      ],
      "metadata": {
        "id": "CgIp5kqK4nkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "spark.sql(\n",
        "    \"SELECT * FROM VALUES ('Hello World'), ('Apache Spark') t(text), \"\n",
        "    \"LATERAL split_words(text)\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6q-KUS4eGr",
        "outputId": "8fa1c6d2-2c0b-4b61-ae5d-cd78a0770c86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|        text|  word|\n",
            "+------------+------+\n",
            "| Hello World| Hello|\n",
            "| Hello World| World|\n",
            "|Apache Spark|Apache|\n",
            "|Apache Spark| Spark|\n",
            "+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TABLE input argument**\n",
        "\n"
      ],
      "metadata": {
        "id": "92xAAYny5AHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udtf\n",
        "from pyspark.sql.types import Row\n",
        "\n",
        "@udtf(returnType=\"id: int\")\n",
        "class FilterUDTF:\n",
        "    def eval(self, row: Row):\n",
        "        if row[\"id\"] > 5:\n",
        "            yield row[\"id\"],\n",
        "\n",
        "spark.udtf.register(\"filter_udtf\", FilterUDTF)\n",
        "\n",
        "spark.sql(\"SELECT * FROM filter_udtf(TABLE(SELECT * FROM range(10)))\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G9bWgLY47kh",
        "outputId": "408e8984-a959-4918-ba84-6e9d6852bc1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  6|\n",
            "|  7|\n",
            "|  8|\n",
            "|  9|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "data1 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\", 1000, \"Sales\", 2020),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\", 2000, \"Operations\",2020),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\", 3000, \"Sales\",2020),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\", 4000, \"Operations\",2020),\n",
        "  (\"Ria\",\"Anne\",\"Jones\",\"60000\",\"F\", 7000, \"Operations\",2020)\n",
        "\n",
        "  ]\n",
        "\n",
        "schema1 = StructType([ \\\n",
        "    StructField(\"firstname\",StringType(),True), \\\n",
        "    StructField(\"middlename\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"annualsalary\", IntegerType(), True),\n",
        "    StructField(\"work\", StringType(), True),\n",
        "    StructField(\"year\", IntegerType(), True),\n",
        "\n",
        "  ])\n",
        "\n",
        "df1 = spark.createDataFrame(data=data1,schema=schema1)\n",
        "df1.show(truncate=False)\n",
        "df1.createOrReplaceTempView(\"sample\")\n",
        "\n",
        "\n",
        "@udtf(returnType=\"id: string, firstname: string, lastname: string\")\n",
        "class SalaryFilterUDTF:\n",
        "    def eval(self, row: Row):\n",
        "        if int(row[\"annualsalary\"]) > 3000:\n",
        "            yield row[\"id\"], row[\"firstname\"],row[\"lastname\"]\n",
        "\n",
        "spark.udtf.register(\"salary_udtf\", SalaryFilterUDTF)\n",
        "\n",
        "spark.sql(\"SELECT * FROM salary_udtf(TABLE(SELECT * FROM sample))\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQyxsTEPv4p",
        "outputId": "c73c5310-6615-4a0a-a42f-5295ccc9f690"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "|firstname|middlename|lastname|id   |gender|annualsalary|work      |year|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "|James    |          |Smith   |36636|M     |1000        |Sales     |2020|\n",
            "|Michael  |Rose      |        |40288|M     |2000        |Operations|2020|\n",
            "|Robert   |          |Williams|42114|M     |3000        |Sales     |2020|\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000        |Operations|2020|\n",
            "|Ria      |Anne      |Jones   |60000|F     |7000        |Operations|2020|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "\n",
            "+-----+---------+--------+\n",
            "|   id|firstname|lastname|\n",
            "+-----+---------+--------+\n",
            "|39192|    Maria|   Jones|\n",
            "|60000|      Ria|   Jones|\n",
            "+-----+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM filter_udtf(TABLE(SELECT * FROM range(10)))\").show()"
      ],
      "metadata": {
        "id": "KVhe_OidP3xX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}